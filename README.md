# ğŸ“š DocMind â€“ RAG Study Bot

DocMind is a **Retrieval-Augmented Generation (RAG)** chatbot built with **Streamlit**, **LangChain**, **ChromaDB**, **Ollama Embeddings**, and **Groq LLM API**.  
It allows you to **upload PDFs/TXT files**, store their embeddings locally, and ask questions with context-aware answers.

---

## ğŸš€ Features
- **Multi-file upload** (PDF & TXT)
- **Local ChromaDB storage** (`./study_db`)
- **Ollama `nomic-embed-text`** embeddings
- **Context retrieval** with top-K similarity search
- **Groq LLM** integration for answering queries
- **Chat history persistence** during a session
- **New Conversation** button to reset state & database

---

## ğŸ“‚ Project Structure
```
.
â”œâ”€â”€ app.py               # Main Streamlit app
â”œâ”€â”€ .env                 # Environment variables (Groq API key, model name)
â”œâ”€â”€ study_db/            # ChromaDB persisted storage
â”œâ”€â”€ images/
â”‚   â””â”€â”€ icon.png         # App icon
â”œâ”€â”€ requirements.txt     # Python dependencies
â””â”€â”€ README.md            # Project documentation
```

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/yourusername/docmind.git
```

### 2ï¸âƒ£ Install dependencies
```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Set up `.env` file
Create a `.env` file in the project root:
```env
groq_api_key=YOUR_GROQ_API_KEY
model_name=llama3-8b-8192  # Example Groq model
```

### 4ï¸âƒ£ Run the app
```bash
streamlit run app.py
```

---

## ğŸ’¡ How It Works
1. **Upload documents** (PDF/TXT) from the sidebar.
2. **Text extraction** â€“ PDFs are read page-by-page, TXT files as a single chunk.
3. **Chunking** â€“ Content is split into 1000-char chunks with 200 overlap.
4. **Embedding** â€“ Chunks are embedded using `nomic-embed-text`.
5. **Vector storage** â€“ Stored in ChromaDB at `./study_db`.
6. **Retrieval** â€“ When you ask a question, the top 5 relevant chunks are fetched.
7. **Augmented prompt** â€“ Retrieved context is sent with your question to Groq LLM.
8. **Response** â€“ LLM generates a context-aware answer.

---

## ğŸ”„ Resetting the Database
Click **Clear DB** in the sidebar to:
- Clear chat history
- Reset the retriever
- (Optional) Delete all stored embeddings

---

## ğŸ–¼ï¸ Screenshot
**On StartUp**
![App Screenshot](./images/1.png)
**File Uploaded**
![App Screenshot](./images/2.png)
**Query Processing**
![App Screenshot](./images/3.png)
**AI Response1**
![App Screenshot](./images/4.png)
![App Screenshot](./images/5.png)
**AI Response2**
![App Screenshot](./images/6.png)
**Quiz**
![App Screenshot](./images/7.png)
**Summarize**
![App Screenshot](./images/8.png)
![App Screenshot](./images/9.png)

